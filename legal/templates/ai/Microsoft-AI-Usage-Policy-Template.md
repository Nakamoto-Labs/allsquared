AI Usage
Policy

Microsoft
Resource Guide
December 2023

This resource guide was commissioned and funded
by Microsoft and was produced in partnership with TechSoup.
Microsoft Copilot was formerly called Bing Chat and Bing Chat Enterprise". Learn more here.

Contents
4

What Is an AI Usage
Policy?

6

Why Create an AI
Usage Policy?

9

Factors to Consider

What Is an AI
Usage Policy?

An AI Usage Policy is a document that outlines the rules and principles for using artificial intelligence (AI)
technologies in an ethical and responsible way within an organization. It is also called an AI Acceptable Use
Policy.
Additionally, a policy document helps your nonprofit follow existing legal and regulatory standards related
to artificial intelligence, protects your nonprofit’s data, and prevents bias and discrimination.
Regardless of your nonprofit’s stance on AI, it is essential to develop, communicate, and implement a clear,
practical policy so employees know what you expect from them regarding the changing technology.
In order to develop an AI policy, you will need to evaluate AI needs and objectives within your nonprofit,
establish a governance framework, train employees, monitor the performance of AI technologies, and finally,
conduct regular reviews of your policy document.
Note: This guide is focused on generative AI solutions as these are currently the most common AI
technologies used by nonprofits. If your organization uses other kinds of AI you will need to adjust the policy
document according to the specific use cases and challenges the technology poses.

What Is an AI Usage Policy?

5

Why Create
an AI Usage
Policy?

Objectives

6

Generative AI and its applications in the nonprofit sector can
be powerful tools for organizations, but they also pose various
challenges. Clear guides and policies help both staff and
external vendors to follow your organization's core values,
ethics, and laws when using AI, and they increase the chances
that they will use such technologies safely and securely.
Nonprofit organizations need to guide staff, volunteers,
contractors, and external stakeholders on how to use these
technologies.

Why Create an AI Usage Policy?

7

These are the main benefits of using a generative AI policy document:
• Ensure compliance and avoid legal and regulatory issues: As AI laws and regulations keep changing, you'll need to
ensure that your nonprofit follows them. You will also need to comply with laws related to data privacy, intellectual
property rights, and consumer protection.
• Establish trust: Organizations using AI systems to generate content are accountable for its quality and accuracy. An
AI policy helps set standards and guidelines to ensure that generated content is reliable and transparent, which is
essential to keeping the trust of donors and other stakeholders.
• Protect sensitive data: Generative AI tools learn from the data you enter into their system, which means that
sensitive or proprietary data can be accessed by the AI tool. A policy can mitigate this risk by setting strict data
protection protocols and educating staff on what data is safe to share.
• Avoid biased or discriminatory output: Generative AI models reflect the characteristics of their training data, which
means that if this data is biased, your output is likely to be as well. Acceptable use policies include measures to
ensure that all AI-generated output is carefully checked to avoid discrimination and bias.
• Encourage a culture of AI awareness: By setting clear expectations and guidelines, employees are made aware of the
risks and motivated to use AI tools responsibly.

Why Create an AI Usage Policy?

8

Factors to
Consider

Before You Begin

9

To create a policy for generative AI tools, nonprofit
organizations need more than just knowledge of the
technology and its possibilities. They also need to create a
framework that defines operational limits and protections
required when using these technologies.
Here are a few important factors to consider when creating a
policy document for generative AI tools.

Factors to Consider

10

Determine the Users of AI
Before creating the policy, consider who will be using AI. Is it the entire team, a single department, or a few specific
people? You will then be able to understand the needs of the team and various use cases for generative AI. Once you
have a clear understanding of who is using AI, and for what purpose, you can clearly define the scope of the policy.

Balance Innovation with Risk Management
Striking a balance between using innovative AI technologies and managing associated risks is crucial. Artificial
intelligence and machine learning models can offer nonprofits significant advantages, but they can also pose a threat
to security, privacy, and fairness. Generative AI can create highly realistic and convincing content that is misleading or
harmful. Consider how you can responsibly promote AI usage and avoid such occurrences. You should focus on risk
identification and mitigation strategies and regularly monitor the AI technology used.
Tip: One way to do this is to document use cases of tasks that are low-risk and high-risk and those that should be
completely avoided so employees are aware of when to use AI. You should also list all the licensed AI tools approved
for use.

Factors to Consider

11

Check for Copyright
Generative AI tools have been trained using information from the Internet. There are growing concerns that some of
this information may be copyrighted or used without the owner's consent. It is important to be aware of this fact while
using such technologies. In the case of generative imaging models, evidence has been presented that some of the
platforms may not recognize, or may even ignore, rules surrounding Creative Commons licensing. Make sure you do
not inadvertently publish copyrighted information and put in place measures to mitigate such an occurrence.

Ensure Data Privacy and Security
A nonprofit’s AI policy should address data privacy and security concerns, ensuring that personal data and sensitive
information are handled securely. This includes defining procedures for data anonymization, consent, access controls,
and compliance with applicable data protection regulations. Provide training sessions and workshops for employees
on topics such as data privacy, security, and ethical use of AI to ensure that staff members are aware of safe practices.
Tip: Consider using enterprise-level generative AI accounts that let nonprofits control important privacy and
information-sharing settings.

Factors to Consider

12

View the Policy as a Working Document
Given the rapid pace of AI evolution, it’s important to regularly review and update your nonprofit’s AI policy.
Monitor changes in technology, regulations, and societal norms and update your policy accordingly. You may also
want to incorporate feedback from employees and other stakeholders. View your policy as a working document
that is reflective of how your nonprofit currently functions and its goals for the future. It should serve as a guide for
your team.

Transparency and Accountability
Stakeholders, including employees, beneficiaries, and partners, should understand how your company uses AI,
what data it is processing, and how decisions are made. Set out clear guidelines on transparency and establish an
accountability framework for any issues arising from AI applications. Providing comprehensive knowledge about AI
and its ethical implications can also help foster a culture of transparency.

Factors to Consider

13

Impact on Staff
Be transparent with staff about introducing AI tools and provide appropriate training and support to help everyone
adapt to changes. Where necessary, consider consulting with experts in the area of technology and organizational
ethics to further discuss the consequences of introducing AI tools into your workplace.

Social Impact
AI has had a significant impact on society, influencing public opinion and affecting decision-making processes. An
AI policy should take this into account and consider the broader societal implications of your AI systems. This can
involve engaging in public discourse, collaborating with external stakeholders, and taking responsibility for the social
consequences of AI-generated content.

Factors to Consider

14

EXAMPLES OF AI USAGE POLICIES

AI USAGE POLICY TEMPLATE

TechSoup AI Usage Policy:
Download the policy here (PDF)

How to Use the Template

Microsoft AI Tools and Resources:
Responsible AI Tools and Practices

You will need to customize this
template in order to use it for your
organization. We have included
spaces for you to enter your
organization’s name, contact
details, and any other customizable
information.
Feel free to include additional
principles or utilization guidelines or
remove those that are not relevant
to your work.

Click here to download the template and create your own AI Usage Policy.

Factors to Consider

15

Note: This guide was produced with the assistance of generative AI (Microsoft Copilot).
Disclaimer: The information provided in this article or otherwise on this website does not, and is not
intended to, constitute legal advice. Instead, all information, content, and strategies discussed herein are
for general informational purposes only. Information on this website may not constitute the most up-to-date
legal or other information, and the contents within this site or article may contain website links to third-party
websites or services. Such links are only for the convenience of the reader; TechSoup nor the author of
posted content make any assurances nor endorse the contents of third-party sites.
TechSoup encourages the readers of this site or article to contact their own attorney to obtain legal advice
with respect to the opinions or content discussed herein. TechSoup nor any authors of posted content
assume any legal liability that may arise from the use of strategies or suggestions posted within. Information
provided on TechSoup’s website does not create an attorney-client relationship between TechSoup and
the readers of its website. Posted content reflects the opinions of the author as an individual, and does not
reflect an official position or legal advice from TechSoup.

Main Office

Press Contact

Affiliate Accounts

Business Development

TechSoup
435 Brannan Street, Suite 100
San Francisco, CA 94107
Email Customer Service at
customerservice@techsoup.org

Email PR at
PR@techsoup.org

Organizations with multiple
members or affiliates, and those
looking to place donation requests
for 20 or more organizations,
please contact us at
mmd@techsoup.org.

For those interested in
donating products, see
Become a Donor Partner.

© Copyright 2023, TechSoup. All rights reserved.
This work is published under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International license.

